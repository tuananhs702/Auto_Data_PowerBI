from googleapiclient.discovery import build
from google.oauth2 import service_account
import os
import io
import json
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# ğŸ”¹ Láº¥y credentials tá»« GitHub Secrets
GDRIVE_CREDENTIALS = json.loads(os.getenv("GDRIVE_CREDENTIALS"))

# ğŸ”¹ Káº¿t ná»‘i vá»›i Google Drive API
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(GDRIVE_CREDENTIALS, scopes=SCOPES)
service = build('drive', 'v3', credentials=creds)

# ğŸ”¹ ID thÆ° má»¥c Google Drive cáº§n táº£i
FOLDER_ID = "1LyQOw0sTGUTGUxxmGZivAzB_aTBdlH6d"
SAVE_PATH = "downloads"

# ğŸ”¹ Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i
os.makedirs(SAVE_PATH, exist_ok=True)

# ğŸ”¹ Láº¥y danh sÃ¡ch file trong thÆ° má»¥c Google Drive
query = f"'{FOLDER_ID}' in parents and trashed=false"
results = service.files().list(q=query, fields="files(id, name)").execute()
files = results.get('files', [])

if not files:
    print("âš ï¸ KhÃ´ng cÃ³ file nÃ o trong thÆ° má»¥c!")
else:
    for file in files:
        file_id = file['id']
        file_name = file['name']
        file_path = os.path.join(SAVE_PATH, file_name)

        # ğŸ”¹ Táº£i file tá»« Google Drive
        request = service.files().get_media(fileId=file_id)
        with open(file_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        print(f"âœ… ÄÃ£ táº£i: {file_name}")

        # ğŸ”¹ Náº¿u file lÃ  Excel, chuyá»ƒn sang CSV
        if file_name.endswith(('.xls', '.xlsx')):
            csv_path = file_path.rsplit('.', 1)[0] + ".csv"
            df = pd.read_excel(file_path)
            df.to_csv(csv_path, index=False)
            os.remove(file_path)  # XÃ³a file gá»‘c Excel
            print(f"ğŸ”„ ÄÃ£ chuyá»ƒn {file_name} thÃ nh {os.path.basename(csv_path)}")

# ğŸ”¹ Cáº­p nháº­t summary_Br_daily.csv tá»« predictions_table_BR_daily.csv
summary_file = os.path.join(SAVE_PATH, "summary_Br_daily.csv")
predictions_file = os.path.join(SAVE_PATH, "predictions_table_BR_daily.csv")

# âœ… Náº¿u file summary chÆ°a tá»“n táº¡i, táº¡o file trá»‘ng
if not os.path.exists(summary_file):
    pd.DataFrame(columns=["Date"]).to_csv(summary_file, index=False)

# âœ… Äá»c dá»¯ liá»‡u tá»« file
df_summary = pd.read_csv(summary_file)
df_predictions = pd.read_csv(predictions_file)

# ğŸ”¹ Äáº£m báº£o cá»™t cÃ³ Ä‘Ãºng tiÃªu Ä‘á»
df_predictions.columns = ["Date", "Predicted", "Upper_Bound", "Lower_Bound"]
df_predictions["Date"] = df_predictions["Date"].astype(str)

# ğŸ”¹ Äá»•i tÃªn cá»™t Ä‘áº§u tiÃªn thÃ nh "Date" náº¿u chÆ°a Ä‘Ãºng
if df_summary.columns[0] != "Date":
    df_summary.rename(columns={df_summary.columns[0]: "Date"}, inplace=True)

# ğŸ› ï¸ Loáº¡i bá» dÃ²ng tiÃªu Ä‘á» bá»‹ chÃ¨n nháº§m
df_predictions = df_predictions[df_predictions["Date"] != "Predicted"]

# ğŸ“Œ Láº¥y danh sÃ¡ch ngÃ y Ä‘Ã£ cÃ³ trong summary
existing_dates = df_summary["Date"].astype(str).tolist()

# ğŸ”„ ThÃªm dá»¯ liá»‡u má»›i tá»« df_predictions vÃ o summary náº¿u ngÃ y Ä‘Ã³ chÆ°a cÃ³
df_new = df_predictions[~df_predictions["Date"].isin(existing_dates)]
df_summary = pd.concat([df_summary, df_new], ignore_index=True)

# ğŸ’¾ LÆ°u láº¡i file summary
df_summary.to_csv(summary_file, index=False)
print(f"âœ… ÄÃ£ cáº­p nháº­t {summary_file} mÃ  khÃ´ng chÃ¨n sai tiÃªu Ä‘á»!")
