from googleapiclient.discovery import build
from google.oauth2 import service_account
import os
import io
import json
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# ğŸ”¹ Láº¥y credentials tá»« GitHub Secrets
GDRIVE_CREDENTIALS = json.loads(os.getenv("GDRIVE_CREDENTIALS"))

# ğŸ”¹ Káº¿t ná»‘i vá»›i Google Drive API
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(GDRIVE_CREDENTIALS, scopes=SCOPES)
service = build('drive', 'v3', credentials=creds)

# ğŸ”¹ ID thÆ° má»¥c Google Drive cáº§n táº£i
FOLDER_ID = "1LyQOw0sTGUTGUxxmGZivAzB_aTBdlH6d"
SAVE_PATH = "downloads"

# ğŸ”¹ Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i
os.makedirs(SAVE_PATH, exist_ok=True)

# ğŸ”¹ Láº¥y danh sÃ¡ch file trong thÆ° má»¥c Google Drive
query = f"'{FOLDER_ID}' in parents and trashed=false"
results = service.files().list(q=query, fields="files(id, name)").execute()
files = results.get('files', [])

if not files:
    print("âš ï¸ KhÃ´ng cÃ³ file nÃ o trong thÆ° má»¥c!")
else:
    for file in files:
        file_id = file['id']
        file_name = file['name']
        file_path = os.path.join(SAVE_PATH, file_name)

        # ğŸ”¹ Táº£i file tá»« Google Drive
        request = service.files().get_media(fileId=file_id)
        with open(file_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        print(f"âœ… ÄÃ£ táº£i: {file_name}")

        # ğŸ”¹ Náº¿u file lÃ  Excel, chuyá»ƒn sang CSV
        if file_name.endswith(('.xls', '.xlsx')):
            csv_path = file_path.rsplit('.', 1)[0] + ".csv"
            df = pd.read_excel(file_path)
            df.to_csv(csv_path, index=False)
            os.remove(file_path)  # XÃ³a file gá»‘c Excel
            print(f"ğŸ”„ ÄÃ£ chuyá»ƒn {file_name} thÃ nh {os.path.basename(csv_path)}")

# ğŸ”¹ Cáº­p nháº­t summary_Br_daily.csv tá»« predictions_table_BR_daily.csv
summary_file = os.path.join(SAVE_PATH, "summary_Br_daily.csv")
predictions_file = os.path.join(SAVE_PATH, "predictions_table_BR_daily.csv")

if os.path.exists(predictions_file) and os.path.exists(summary_file):
    df_predictions = pd.read_csv(predictions_file)
    df_summary = pd.read_csv(summary_file)

    # âœ… Äáº·t tÃªn cá»™t Ä‘áº§u tiÃªn lÃ  "Date" náº¿u chÆ°a cÃ³
    df_predictions.rename(columns={df_predictions.columns[0]: "Date"}, inplace=True)
    df_summary.rename(columns={df_summary.columns[0]: "Date"}, inplace=True)

    # ğŸ”¹ TÃ¬m nhá»¯ng ngÃ y cÃ³ trong predictions nhÆ°ng chÆ°a cÃ³ trong summary
    missing_dates = df_predictions[~df_predictions["Date"].isin(df_summary["Date"])]

    if not missing_dates.empty:
        # ğŸ”¹ Chá»‰ láº¥y cÃ¡c cá»™t cáº§n thiáº¿t tá»« predictions
        missing_data = missing_dates[["Date", "Fitting", "True_value"]].copy()

        # âœ… Äáº£m báº£o 3 cá»™t cuá»‘i cÃ³ tÃªn chÃ­nh xÃ¡c
        expected_columns = ["Predicted", "Upper_Bound", "Lower_Bound"]
        for i, col_name in enumerate(expected_columns, start=len(df_summary.columns) - 3):
            if i >= len(df_summary.columns):  
                df_summary[col_name] = None  # ThÃªm cá»™t má»›i
            else:
                df_summary.rename(columns={df_summary.columns[i]: col_name}, inplace=True)

        # ğŸ”¹ Gá»™p dá»¯ liá»‡u vÃ o summary
        df_summary = pd.concat([df_summary, missing_data], ignore_index=True)

        # âœ… LÆ°u láº¡i file summary
        df_summary.to_csv(summary_file, index=False)
        print("âœ… ÄÃ£ cáº­p nháº­t file summary_Br_daily.csv")
    else:
        print("âš¡ KhÃ´ng cÃ³ ngÃ y má»›i cáº§n thÃªm!")
else:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y file predictions_table_BR_daily.csv hoáº·c summary_Br_daily.csv")
