from googleapiclient.discovery import build
from google.oauth2 import service_account
import os
import io
import json
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# ğŸ”¹ Láº¥y credentials tá»« GitHub Secrets
GDRIVE_CREDENTIALS = json.loads(os.getenv("GDRIVE_CREDENTIALS"))

# ğŸ”¹ Káº¿t ná»‘i vá»›i Google Drive API
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(GDRIVE_CREDENTIALS, scopes=SCOPES)
service = build('drive', 'v3', credentials=creds)

# ğŸ”¹ ID thÆ° má»¥c Google Drive cáº§n táº£i
FOLDER_ID = "1LyQOw0sTGUTGUxxmGZivAzB_aTBdlH6d"
SAVE_PATH = "downloads"

# ğŸ”¹ Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i
os.makedirs(SAVE_PATH, exist_ok=True)

# ğŸ”¹ Láº¥y danh sÃ¡ch file trong thÆ° má»¥c Google Drive
query = f"'{FOLDER_ID}' in parents and trashed=false"
results = service.files().list(q=query, fields="files(id, name)").execute()
files = results.get('files', [])

if not files:
    print("âš ï¸ KhÃ´ng cÃ³ file nÃ o trong thÆ° má»¥c!")
else:
    for file in files:
        file_id = file['id']
        file_name = file['name']
        file_path = os.path.join(SAVE_PATH, file_name)

        # ğŸ”¹ Táº£i file tá»« Google Drive
        request = service.files().get_media(fileId=file_id)
        with open(file_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        print(f"âœ… ÄÃ£ táº£i: {file_name}")

        # ğŸ”¹ Náº¿u file lÃ  Excel, chuyá»ƒn sang CSV
        if file_name.endswith(('.xls', '.xlsx')):
            csv_path = file_path.rsplit('.', 1)[0] + ".csv"
            df = pd.read_excel(file_path)
            df.to_csv(csv_path, index=False)
            os.remove(file_path)  # XÃ³a file gá»‘c Excel
            print(f"ğŸ”„ ÄÃ£ chuyá»ƒn {file_name} thÃ nh {os.path.basename(csv_path)}")

# ğŸ”¹ Cáº­p nháº­t summary_Br_daily.csv tá»« predictions_table_BR_daily.csv
summary_file = os.path.join(SAVE_PATH, "summary_Br_daily.csv")
predictions_file = os.path.join(SAVE_PATH, "predictions_table_BR_daily.csv")

if os.path.exists(summary_file) and os.path.exists(predictions_file):
    # ğŸ“Œ Äá»c dá»¯ liá»‡u
    df_summary = pd.read_csv(summary_file)
    df_predictions = pd.read_csv(predictions_file, header=None, names=["Date", "Predicted", "Upper_Bound", "Lower_Bound"])

    # ğŸ“… Láº¥y danh sÃ¡ch ngÃ y má»›i tá»« file dá»± Ä‘oÃ¡n
    new_dates = df_predictions["Date"].astype(str).tolist()
    existing_dates = df_summary.iloc[:, 0].astype(str).tolist()  # Láº¥y cá»™t ngÃ y tá»« summary

    missing_dates = [date for date in new_dates if date not in existing_dates]

    if missing_dates:
        # ğŸ†• Láº¥y dá»¯ liá»‡u tá»« predictions_table_BR_daily.csv cho cÃ¡c ngÃ y má»›i
        new_data = df_predictions[df_predictions["Date"].isin(missing_dates)]

        # âœ… ThÃªm vÃ o summary_Br_daily.csv
        df_summary = pd.concat([df_summary, new_data], ignore_index=True)

    # ğŸ’¾ LÆ°u láº¡i file summary
    df_summary.to_csv(summary_file, index=False)
    print(f"âœ… ÄÃ£ cáº­p nháº­t {summary_file}")
else:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cáº£ 2 file summary_Br_daily.csv vÃ  predictions_table_BR_daily.csv!")
