from googleapiclient.discovery import build
from google.oauth2 import service_account
import os
import io
import json
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# ğŸ”¹ Láº¥y credentials tá»« GitHub Secrets
GDRIVE_CREDENTIALS = json.loads(os.getenv("GDRIVE_CREDENTIALS"))

# ğŸ”¹ Káº¿t ná»‘i vá»›i Google Drive API
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(GDRIVE_CREDENTIALS, scopes=SCOPES)
service = build('drive', 'v3', credentials=creds)

# ğŸ”¹ ID thÆ° má»¥c Google Drive cáº§n táº£i
FOLDER_ID = "1LyQOw0sTGUTGUxxmGZivAzB_aTBdlH6d"
SAVE_PATH = "downloads"

# ğŸ”¹ Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i
os.makedirs(SAVE_PATH, exist_ok=True)

# ğŸ”¹ Láº¥y danh sÃ¡ch file trong thÆ° má»¥c Google Drive
query = f"'{FOLDER_ID}' in parents and trashed=false"
results = service.files().list(q=query, fields="files(id, name)").execute()
files = results.get('files', [])

if not files:
    print("âš ï¸ KhÃ´ng cÃ³ file nÃ o trong thÆ° má»¥c!")
else:
    for file in files:
        file_id = file['id']
        file_name = file['name']
        file_path = os.path.join(SAVE_PATH, file_name)

        # ğŸ”¹ Táº£i file tá»« Google Drive
        request = service.files().get_media(fileId=file_id)
        with open(file_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        print(f"âœ… ÄÃ£ táº£i: {file_name}")

        # ğŸ”¹ Náº¿u file lÃ  Excel, chuyá»ƒn sang CSV
        if file_name.endswith(('.xls', '.xlsx')):
            csv_path = file_path.rsplit('.', 1)[0] + ".csv"
            df = pd.read_excel(file_path)
            df.to_csv(csv_path, index=False)
            os.remove(file_path)  # XÃ³a file gá»‘c Excel
            print(f"ğŸ”„ ÄÃ£ chuyá»ƒn {file_name} thÃ nh {os.path.basename(csv_path)}")

# ğŸ”¹ Cáº­p nháº­t summary_Br_daily.csv tá»« predictions_table_BR_daily.csv
summary_file = os.path.join(SAVE_PATH, "summary_Br_daily.csv")
predictions_file = os.path.join(SAVE_PATH, "predictions_table_BR_daily.csv")

if os.path.exists(summary_file) and os.path.exists(predictions_file):
    # ğŸ“Œ Äá»c dá»¯ liá»‡u
    df_summary = pd.read_csv(summary_file)
    df_predictions = pd.read_csv(predictions_file, header=None)

    # ğŸ”¹ Äáº·t tÃªn cá»™t Ä‘áº§u tiÃªn lÃ  "Date"
    df_summary.rename(columns={df_summary.columns[0]: "Date"}, inplace=True)

    # ğŸ“… Láº¥y danh sÃ¡ch ngÃ y má»›i tá»« file dá»± Ä‘oÃ¡n
    df_predictions.rename(columns={0: "Date"}, inplace=True)
    
    # Kiá»ƒm tra náº¿u file dá»± Ä‘oÃ¡n cÃ³ nhiá»u hÆ¡n 1 cá»™t, thÃªm cÃ¡c cá»™t vÃ o summary
    if df_predictions.shape[1] > 1:
        new_columns = df_predictions.columns[1:].tolist()
        for col in new_columns:
            if col not in df_summary.columns:
                df_summary[col] = None  # Táº¡o cá»™t náº¿u chÆ°a cÃ³

    # ğŸŒŸ ThÃªm ngÃ y má»›i vÃ o summary náº¿u chÆ°a cÃ³
    existing_dates = df_summary["Date"].astype(str).tolist()  # Láº¥y cá»™t ngÃ y tá»« summary
    new_rows = df_predictions[~df_predictions["Date"].astype(str).isin(existing_dates)]

    if not new_rows.empty:
        df_summary = pd.concat([df_summary, new_rows], ignore_index=True)

    # ğŸ’¾ LÆ°u láº¡i file summary
    df_summary.to_csv(summary_file, index=False)
    print(f"âœ… ÄÃ£ cáº­p nháº­t {summary_file}")
else:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cáº£ 2 file summary_Br_daily.csv vÃ  predictions_table_BR_daily.csv!")
