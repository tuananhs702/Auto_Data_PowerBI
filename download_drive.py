from googleapiclient.discovery import build
from google.oauth2 import service_account
import os
import io
import json
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# üîπ L·∫•y credentials t·ª´ GitHub Secrets
GDRIVE_CREDENTIALS = json.loads(os.getenv("GDRIVE_CREDENTIALS"))

# üîπ K·∫øt n·ªëi v·ªõi Google Drive API
SCOPES = ['https://www.googleapis.com/auth/drive']
creds = service_account.Credentials.from_service_account_info(GDRIVE_CREDENTIALS, scopes=SCOPES)
service = build('drive', 'v3', credentials=creds)

# üîπ ID th∆∞ m·ª•c Google Drive c·∫ßn t·∫£i
FOLDER_ID = "1LyQOw0sTGUTGUxxmGZivAzB_aTBdlH6d"
SAVE_PATH = "downloads"

# üîπ T·∫°o th∆∞ m·ª•c downloads n·∫øu ch∆∞a t·ªìn t·∫°i
os.makedirs(SAVE_PATH, exist_ok=True)

# üîπ L·∫•y danh s√°ch file trong th∆∞ m·ª•c Google Drive
query = f"'{FOLDER_ID}' in parents and trashed=false"
results = service.files().list(q=query, fields="files(id, name)").execute()
files = results.get('files', [])

if not files:
    print("‚ö†Ô∏è Kh√¥ng c√≥ file n√†o trong th∆∞ m·ª•c!")
else:
    for file in files:
        file_id = file['id']
        file_name = file['name']
        file_path = os.path.join(SAVE_PATH, file_name)

        # üîπ T·∫£i file t·ª´ Google Drive
        request = service.files().get_media(fileId=file_id)
        with open(file_path, "wb") as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        print(f"‚úÖ ƒê√£ t·∫£i: {file_name}")

        # üîπ N·∫øu file l√† Excel, chuy·ªÉn sang CSV
        if file_name.endswith(('.xls', '.xlsx')):
            csv_path = file_path.rsplit('.', 1)[0] + ".csv"
            df = pd.read_excel(file_path)
            df.to_csv(csv_path, index=False)
            os.remove(file_path)  # X√≥a file g·ªëc Excel
            print(f"üîÑ ƒê√£ chuy·ªÉn {file_name} th√†nh {os.path.basename(csv_path)}")

# üîπ C·∫≠p nh·∫≠t summary_Br_daily.csv t·ª´ predictions_table_BR_daily.csv
predictions_file = os.path.join(SAVE_PATH, "predictions_table_BR_daily.csv")
summary_file = os.path.join(SAVE_PATH, "summary_Br_daily.csv")

# Ki·ªÉm tra n·∫øu c·∫£ hai file t·ªìn t·∫°i
if os.path.exists(predictions_file) and os.path.exists(summary_file):
    # ƒê·ªçc file predictions (ch·ªâ l·∫•y c·ªôt ƒë·∫ßu ti√™n l√† ng√†y)
    df_pred = pd.read_csv(predictions_file, header=None, usecols=[0], names=['date'])

    # ƒê·ªçc file summary (gi·ªØ nguy√™n t·∫•t c·∫£ c√°c c·ªôt)
    df_summary = pd.read_csv(summary_file, header=None)

    # Gi·∫£ s·ª≠ c·ªôt ng√†y l√† c·ªôt ƒë·∫ßu ti√™n trong summary
    df_summary.columns = ['date'] + [f'col_{i}' for i in range(1, df_summary.shape[1])]

    # T√¨m c√°c ng√†y m·ªõi c√≥ trong df_pred nh∆∞ng kh√¥ng c√≥ trong df_summary
    existing_dates = set(df_summary['date'].astype(str))
    new_dates = df_pred[~df_pred['date'].astype(str).isin(existing_dates)]

    if not new_dates.empty:
        # T·∫°o dataframe m·ªõi v·ªõi gi√° tr·ªã 0 cho c√°c c·ªôt c√≤n l·∫°i
        num_columns = df_summary.shape[1] - 1  # S·ªë l∆∞·ª£ng c·ªôt d·ªØ li·ªáu tr·ª´ c·ªôt 'date'
        new_rows = pd.DataFrame(0, index=new_dates.index, columns=df_summary.columns)
        new_rows['date'] = new_dates['date']  # G√°n c·ªôt ng√†y

        # G·ªôp v√†o summary, gi·ªØ ng√†y duy nh·∫•t
        df_summary = pd.concat([df_summary, new_rows], ignore_index=True)
        df_summary.drop_duplicates(subset=['date'], keep='first', inplace=True)

        # L∆∞u l·∫°i file summary v·ªõi t·∫•t c·∫£ c√°c c·ªôt
        df_summary.to_csv(summary_file, index=False, header=False)
        print(f"‚úÖ ƒê√£ th√™m {len(new_dates)} ng√†y m·ªõi v·ªõi c√°c gi√° tr·ªã 0 v√†o {summary_file}")
    else:
        print("‚úÖ Kh√¥ng c√≥ ng√†y m·ªõi c·∫ßn th√™m.")
else:
    print("‚ö†Ô∏è M·ªôt trong hai file kh√¥ng t·ªìn t·∫°i!")
# Ki·ªÉm tra n·∫øu file summary t·ªìn t·∫°i
if os.path.exists(summary_file):
    # ƒê·ªçc file summary
    df_summary = pd.read_csv(summary_file)

    # Th√™m 3 c·ªôt tr·ªëng n·∫øu ch∆∞a c√≥
    for col in ["Predicted", "Upper_Bound", "Lower_Bound"]:
        if col not in df_summary.columns:
            df_summary[col] = ""

    # L∆∞u l·∫°i file summary
    df_summary.to_csv(summary_file, index=False)
    print(f"‚úÖ ƒê√£ th√™m 3 c·ªôt tr·ªëng v√†o {summary_file}")
else:
    print("‚ö†Ô∏è File summary_Br_daily.csv kh√¥ng t·ªìn t·∫°i!")
